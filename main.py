"""
NewsRadar v7.0 - Hybrid Free Edition
Powered by Asyncio Queues & Smart Deduplication
"""

import os
import sys
import time
import asyncio
import logging
import re
import html
import hashlib
import random
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Optional, List, Set

import motor.motor_asyncio
from telethon import TelegramClient, events
from telethon.sessions import StringSession
from telethon import errors

# Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø¯Ù‡ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ø³Ø±ÙˆØ± (Ø§Ú¯Ø± ÙˆØ¨â€ŒØ³Ø±ÙˆØ± Ø¯Ø§Ø±ÛŒØ¯)
try:
    from web_server import keep_alive
except ImportError:
    def keep_alive(): pass

# ============================================================================
# 1. CONFIGURATION (ØªÙ†Ø¸ÛŒÙ…Ø§Øª)
# ============================================================================
@dataclass(frozen=True)
class Config:
    API_ID: int
    API_HASH: str
    STRING_SESSION: str
    TARGET_CHANNEL: str
    MONGO_URI: str
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯
    MAX_QUEUE_SIZE: int = 100       # Ø¸Ø±ÙÛŒØª ØµÙ Ø¯Ø§Ø®Ù„ÛŒ
    DUPLICATE_TTL: int = 86400 * 3  # Ø­Ø§ÙØ¸Ù‡ ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ (3 Ø±ÙˆØ²)
    
    # Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§
    NEWS_CHANNELS: tuple = (
        "BBCPersian", "RadioFarda", "Tasnimnews", 
        "deutsch_news1", "khabarfuri", "KHABAREROOZ_IR", "euronewspe"
    )
    
    PROXY_CHANNELS: tuple = (
        "iProxyem", "Proxymelimon", "famoushaji", 
        "V2rrayVPN", "napsternetv", "v2rayng_vpn", "v2rayng_org"
    )

    BLACKLIST: tuple = (
        "Ø¹Ø¶Ùˆ Ø´ÙˆÛŒØ¯", "join", "ØªØ¨Ù„ÛŒØº", "Ø±Ø²Ø±Ùˆ", "bet", "Ø³Ø§ÛŒØª", "Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯",
        "https://t.me", "@", "insta", "youtube"
    )

    SIG_NEWS = "\n\nğŸ“¡ <b>Ø±Ø§Ø¯Ø§Ø± Ø§Ø®Ø¨Ø§Ø±</b>\nğŸ†” @NewsRadar_hub"
    SIG_PROXY = "\n\nğŸ” <b>Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø®ØªØµØ§ØµÛŒ</b>\nğŸ†” @NewsRadar_hub"

    @classmethod
    def from_env(cls):
        return cls(
            API_ID=int(os.getenv("TELEGRAM_API_ID", "0")),
            API_HASH=os.getenv("TELEGRAM_API_HASH", ""),
            STRING_SESSION=os.getenv("STRING_SESSION", ""),
            TARGET_CHANNEL=os.getenv("TARGET_CHANNEL", ""),
            MONGO_URI=os.getenv("MONGO_URI", "mongodb://localhost:27017"),
        )

# ============================================================================
# 2. ADVANCED LOGGING (Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ)
# ============================================================================
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger("NewsRadar-v7")

# ============================================================================
# 3. SMART LOGIC (Ù…ØºØ² Ù…ØªÙÚ©Ø±)
# ============================================================================
class ContentEngine:
    """Ù…ÙˆØªÙˆØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù†Ø³Ø®Ù‡ Enterprise"""
    
    # Ø±Ø¬Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ù‚ÛŒÙ‚
    PROXY_PATTERN = re.compile(r'(vmess|vless|trojan|ss)://[a-zA-Z0-9\-_@:/?=&%.]+')
    URL_CLEANER = re.compile(r'https?://\S+')
    MENTION_CLEANER = re.compile(r'@[a-zA-Z0-9_]+')

    @staticmethod
    def get_content_hash(text: str) -> str:
        """Ø³Ø§Ø®Øª Ø§Ø«Ø± Ø§Ù†Ú¯Ø´Øª ÛŒÚ©ØªØ§ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØªÙˆØ§ (Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯)"""
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ: Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ùˆ Ú©ÙˆÚ†Ú© Ú©Ø±Ø¯Ù† Ø­Ø±ÙˆÙ
        normalized = re.sub(r'\s+', '', text.lower().strip())
        return hashlib.sha256(normalized.encode('utf-8')).hexdigest()

    @classmethod
    def process_proxy(cls, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ù„Ù…"""
        if not text: return []
        configs = cls.PROXY_PATTERN.findall(text)
        # Ø­Ø°Ù Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ ÛŒØ§ Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡
        valid_configs = [c for c in configs if len(c) > 50]
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± ÛŒÚ© Ù¾ÛŒØ§Ù…
        return list(set(valid_configs))

    @classmethod
    def process_news(cls, text: str, blacklist: tuple) -> Optional[str]:
        """ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù…ØªÙ† Ø®Ø¨Ø±"""
        if not text: return None
        
        # Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª Ø¨Ù„Ú©â€ŒÙ„ÛŒØ³Øª
        for bad in blacklist:
            if bad in text:
                text = text.replace(bad, "")

        # Ø­Ø°Ù Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ùˆ Ù…Ù†Ø´Ù†â€ŒÙ‡Ø§
        text = cls.MENTION_CLEANER.sub('', text)
        
        # ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        text = re.sub(r'\n{3,}', '\n\n', text).strip()
        
        if len(text) < 30: return None  # Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø§Ø±Ø²Ø´ Ù†Ø¯Ø§Ø±Ù†Ø¯
        return text

    @staticmethod
    def detect_topic(text: str) -> str:
        """ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø±Ø§ÛŒ Ø§Ù…ÙˆØ¬ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
        t = text.lower()
        if any(x in t for x in ['ÙÙˆØ±ÛŒ', 'breaking', 'urgent']): return 'ğŸ”´'
        if any(x in t for x in ['Ø§Ù‚ØªØµØ§Ø¯', 'Ø¯Ù„Ø§Ø±', 'Ø·Ù„Ø§']): return 'ğŸ’°'
        if any(x in t for x in ['Ø¬Ù†Ú¯', 'Ø­Ù…Ù„Ù‡', 'war']): return 'âš”ï¸'
        if any(x in t for x in ['ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ', 'ai', 'tech']): return 'ğŸ¤–'
        return 'ğŸ“°'

# ============================================================================
# 4. DATABASE & MEMORY (Ø­Ø§ÙØ¸Ù‡ Ø¨Ù„Ù†Ø¯ Ù…Ø¯Øª)
# ============================================================================
class Database:
    def __init__(self, uri: str):
        self.client = motor.motor_asyncio.AsyncIOMotorClient(uri)
        self.db = self.client.newsradar_v7
        self.history = self.db.history

    async def initialize(self):
        # Ø³Ø§Ø®Øª Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø®ÙˆØ¯Ú©Ø§Ø± Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ (TTL)
        await self.history.create_index("created_at", expireAfterSeconds=Config.DUPLICATE_TTL)
        await self.history.create_index("content_hash", unique=True)

    async def is_duplicate(self, content_hash: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±ÛŒØ¹ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
        found = await self.history.find_one({"content_hash": content_hash})
        return found is not None

    async def save_hash(self, content_hash: str, source: str):
        """Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø´ Ø¨Ø±Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡"""
        try:
            await self.history.insert_one({
                "content_hash": content_hash,
                "source": source,
                "created_at": datetime.now(timezone.utc)
            })
        except Exception:
            pass  # Ø§Ú¯Ø± ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯ Ùˆ Ù‡Ù…Ø²Ù…Ø§Ù† Ø«Ø¨Øª Ø´Ø¯ØŒ Ù…Ø´Ú©Ù„ÛŒ Ù†ÛŒØ³Øª

# ============================================================================
# 5. WORKER SYSTEM (Ø³ÛŒØ³ØªÙ… ØµÙ Ùˆ Ø§Ù†ØªØ´Ø§Ø±)
# ============================================================================
class QueueWorker:
    def __init__(self, client: TelegramClient, config: Config, db: Database):
        self.client = client
        self.config = config
        self.db = db
        self.queue = asyncio.Queue(maxsize=config.MAX_QUEUE_SIZE)
        
    async def add_task(self, task_type: str, data: dict):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ ØµÙ (Ø¨Ø¯ÙˆÙ† Ù…Ø³Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡)"""
        try:
            self.queue.put_nowait((task_type, data))
        except asyncio.QueueFull:
            logger.warning("Queue is full! Dropping oldest item.")
            try:
                self.queue.get_nowait()
                self.queue.put_nowait((task_type, data))
            except: pass

    async def start_consumer(self):
        """Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ ØµÙ (Publisher)"""
        logger.info("ğŸ‘· Worker started processing queue...")
        
        while True:
            # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² ØµÙ
            task_type, data = await self.queue.get()
            
            try:
                if task_type == 'proxy':
                    await self._publish_proxy(data)
                elif task_type == 'news':
                    await self._publish_news(data)
                
                # Ø§Ø³ØªØ±Ø§Ø­Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ (Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² FloodWait)
                await asyncio.sleep(random.uniform(2.0, 4.0))
                
            except Exception as e:
                logger.error(f"Publish Error: {e}")
            finally:
                self.queue.task_done()

    async def _publish_proxy(self, data):
        config = data['config']
        # ÙØ±Ù…Øª Ø´ÛŒÚ© Ø¨Ø±Ø§ÛŒ Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù†
        msg = f"ğŸ”‘ <b>Connect to Freedom</b>\n\n<code>{config}</code>{self.config.SIG_PROXY}"
        await self.client.send_message(
            self.config.TARGET_CHANNEL, 
            msg, 
            parse_mode='html', 
            link_preview=False
        )
        logger.info(f"âœ… Proxy Published (Source: {data['source']})")

    async def _publish_news(self, data):
        text = data['text']
        media = data.get('media')
        emoji = ContentEngine.detect_topic(text)
        
        # ÙØ±Ù…Øª Ø®Ø¨Ø±
        header = text.split('\n')[0]
        body = '\n'.join(text.split('\n')[1:])
        formatted_text = f"<b>{emoji} {header}</b>\n\n{body}{self.config.SIG_NEWS}"
        
        if media:
            await self.client.send_file(
                self.config.TARGET_CHANNEL,
                media,
                caption=formatted_text,
                parse_mode='html'
            )
        else:
            await self.client.send_message(
                self.config.TARGET_CHANNEL,
                formatted_text,
                parse_mode='html',
                link_preview=False
            )
        logger.info(f"ğŸ“° News Published (Source: {data['source']})")

# ============================================================================
# 6. MAIN CONTROLLER (Ú©Ù†ØªØ±Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§ØµÙ„ÛŒ)
# ============================================================================
async def main():
    config = Config.from_env()
    
    # Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    db = Database(config.MONGO_URI)
    await db.initialize()
    
    # Ø±Ø§Ù‡ Ø§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù„Ø§ÛŒÙ†Øª ØªÙ„Ú¯Ø±Ø§Ù…
    client = TelegramClient(
        StringSession(config.STRING_SESSION),
        config.API_ID,
        config.API_HASH
    )
    
    # Ø±Ø§Ù‡ Ø§Ù†Ø¯Ø§Ø²ÛŒ ÙˆØ±Ú©Ø±
    worker = QueueWorker(client, config, db)

    @client.on(events.NewMessage(chats=config.NEWS_CHANNELS + config.PROXY_CHANNELS))
    async def handler(event):
        try:
            chat = await event.get_chat()
            channel_name = chat.username or chat.title
            text = event.message.text or ""
            
            # --- Ø­Ø§Ù„Øª Ù¾Ø±ÙˆÚ©Ø³ÛŒ ---
            if channel_name in config.PROXY_CHANNELS:
                configs = ContentEngine.process_proxy(text)
                for conf in configs:
                    # ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´ Ø§Ø² Ø®ÙˆØ¯ Ú©Ø§Ù†ÙÛŒÚ¯ (Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ú©Ø§Ù†ÙÛŒÚ¯ ØªÚ©Ø±Ø§Ø±ÛŒ)
                    conf_hash = ContentEngine.get_content_hash(conf)
                    
                    if not await db.is_duplicate(conf_hash):
                        await db.save_hash(conf_hash, channel_name)
                        await worker.add_task('proxy', {'config': conf, 'source': channel_name})
            
            # --- Ø­Ø§Ù„Øª Ø®Ø¨Ø± ---
            elif channel_name in config.NEWS_CHANNELS:
                clean_text = ContentEngine.process_news(text, config.BLACKLIST)
                if clean_text:
                    # ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´ Ø§Ø² Ù…ØªÙ† ØªÙ…ÛŒØ² Ø´Ø¯Ù‡ (Ø§Ú¯Ø± Ø¯Ùˆ Ú©Ø§Ù†Ø§Ù„ ÛŒÚ© Ø®Ø¨Ø± Ø±Ø§ Ø¨Ú¯Ø°Ø§Ø±Ù†Ø¯ØŒ Ø¯ÙˆÙ…ÛŒ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯)
                    news_hash = ContentEngine.get_content_hash(clean_text)
                    
                    if not await db.is_duplicate(news_hash):
                        await db.save_hash(news_hash, channel_name)
                        
                        media = None
                        if event.message.media:
                            # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯ÛŒØ§ ÙÙ‚Ø· Ø§Ú¯Ø± ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯
                            media = await event.message.download_media(file=bytes)
                        
                        await worker.add_task('news', {
                            'text': clean_text, 
                            'media': media, 
                            'source': channel_name
                        })

        except Exception as e:
            logger.error(f"Handler Error: {e}")

    # Ø´Ø±ÙˆØ¹ Ø¨Ø±Ù†Ø§Ù…Ù‡
    await client.start()
    logger.info("ğŸš€ NewsRadar v7.0 (Hybrid) Started!")
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ ØµÙ
    asyncio.create_task(worker.start_consumer())
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ø§ÙˆÙ…
    await client.run_until_disconnected()

if __name__ == "__main__":
    keep_alive()
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
    except Exception as e:
        logger.critical(f"Fatal Error: {e}")
